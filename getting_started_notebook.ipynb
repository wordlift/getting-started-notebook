{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "Jumpstart a Graph in a few steps with WordLift by providing an XML sitemap and a WordLift Key ([get it here](https://wordlift.io)).\n",
    "\n",
    "This is the first notebook of a series, once you created your graph, move forward to [create internal links](create_internal_links.ipynb).\n",
    "\n",
    "## Video Walkthrough\n",
    "\n",
    "[![Jumpstart your Graph in less than 5 minutes](https://img.youtube.com/vi/yQV9DkH9LmI/0.jpg)](https://www.youtube.com/watch?v=yQV9DkH9LmI)\n",
    "\n",
    "## Configuration\n",
    "\n",
    "There are two configuration sources, at least one of the two is needed, and they're applied in order:\n",
    "\n",
    "1. A file config/default.py\n",
    "2. Local constants and WordLift Key in Google Colab Secrets\n",
    "\n",
    "There are only three configuration settings:\n",
    "\n",
    "* `WORDLIFT_KEY`, holding the WordLift Key, when using Google Colab, it can be set in the secrets\n",
    "* `SITEMAP_URL`, the URL to the sitemap which contains URLs (not other sitemaps, or at least we didn't test it with links to other sitemaps)\n",
    "* `OUTPUT_TYPE`, optional, this is the type used to represent imported web pages. If not set will default to `http://schema.org/WebPage` (other options could be `http://schema.org/CollectionPage`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections.abc import Awaitable\n",
    "\n",
    "from wordlift_sdk.notebook import install_if_missing\n",
    "\n",
    "logging.basicConfig(level=logging.WARNING, force=True)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Configuration from config/default.py file.\n",
    "try:\n",
    "    # Configuration is in the `config/default.py` file.\n",
    "    from config import default as config\n",
    "\n",
    "    WORDLIFT_KEY = config.WORDLIFT_KEY\n",
    "    OUTPUT_TYPES = {config.OUTPUT_TYPE} or {\"http://schema.org/WebPage\"}\n",
    "    SITEMAP_URL = config.SITEMAP_URL\n",
    "except ImportError:\n",
    "    logging.warning(\"Cannot import configuration from local `config/default.py` file.\")\n",
    "\n",
    "# Configuration from Google Colab Secrets.\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "\n",
    "    WORDLIFT_KEY = userdata.get(\"WORDLIFT_KEY\")\n",
    "    OUTPUT_TYPES = {\"http://schema.org/WebPage\"}\n",
    "    SITEMAP_URL = None\n",
    "except ImportError:\n",
    "    logging.warning(\"Cannot import configuration from google.colab.usermap.\")\n",
    "\n",
    "if WORDLIFT_KEY is None or OUTPUT_TYPES is None or SITEMAP_URL is None:\n",
    "    raise ValueError(\"Configuration not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "This part is only for Google Colab. When the notebook is used locally we recommend using `poetry install`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_if_missing(\"wordlift-client>=1.75.0,<2.0.0)\", \"wordlift-client\")\n",
    "install_if_missing(\"beautifulsoup4>=4.13.3,<5.0.0)\", \"beautifulsoup4\")\n",
    "install_if_missing(\"rdflib>=7.1.3,<8.0.0)\", \"rdflib\")\n",
    "install_if_missing(\"tenacity>=9.0.0,<10.0.0)\", \"tenacity\")\n",
    "install_if_missing(\"pycountry>=24.6.1,<25.0.0)\", \"pycountry\")\n",
    "install_if_missing(\n",
    "    \"wordlift-sdk @ git+https://github.com/wordlift/python-sdk.git@0.26.0\",\n",
    "    \"wordlift_sdk\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "This section provides general imports and basic configuration, no need to do anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from rdflib import URIRef, Literal\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from wordlift_client import (\n",
    "    SitemapImportsApi,\n",
    "    SitemapImportRequest,\n",
    "    EmbeddingRequest,\n",
    "    EntityPatchRequest,\n",
    ")\n",
    "from wordlift_sdk.client import ClientConfigurationFactory\n",
    "from wordlift_sdk.utils import (\n",
    "    create_entity_patch_request,\n",
    "    create_or_update_kg_using_sitemap,\n",
    ")\n",
    "from wordlift_client import Configuration\n",
    "from typing import Callable\n",
    "\n",
    "# Defining the host is optional and defaults to https://api.wordlift.io\n",
    "# See configuration.py for a list of all supported configuration parameters.\n",
    "api_url = \"https://api.wordlift.io\"\n",
    "configuration = ClientConfigurationFactory(key=WORDLIFT_KEY).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "There are two callbacks that you can customize according to your needs:\n",
    "\n",
    "1. `import_url`, imports a URL into the Graph, it is called for each URL found in the sitemap.\n",
    "2. `parse_html`, parses the webpage and provides a list of entity patches to add additional properties to the imported entities and is called for every url.\n",
    "\n",
    "## Import URL\n",
    "\n",
    "The defaults work nicely for most situations so that you don't really need to configure anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_url_factory(\n",
    "    configuration: Configuration, types: set[str]\n",
    ") -> Callable[[set[str]], Awaitable[None]]:\n",
    "    @retry(stop=stop_after_attempt(5), wait=wait_fixed(2))\n",
    "    async def import_url(url_list: set[str]) -> None:\n",
    "        import wordlift_client\n",
    "\n",
    "        async with wordlift_client.ApiClient(configuration) as api_client:\n",
    "            imports_api = SitemapImportsApi(api_client)\n",
    "            request = SitemapImportRequest(\n",
    "                embedding=EmbeddingRequest(\n",
    "                    properties=[\n",
    "                        \"http://schema.org/headline\",\n",
    "                        \"http://schema.org/abstract\",\n",
    "                        \"http://schema.org/text\",\n",
    "                    ]\n",
    "                ),\n",
    "                output_types=list(types),\n",
    "                urls=list(url_list),\n",
    "                overwrite=True,\n",
    "                id_generator=\"headline-with-url-hash\",\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                await imports_api.create_sitemap_import(sitemap_import_request=request)\n",
    "            except Exception as e:\n",
    "                logger.error(\"Error importing URLs: %s\", e)\n",
    "\n",
    "    return import_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Parse HTML\n",
    "\n",
    "This example shows how to add `schema:keywords` to an imported entity by taking the values from the `<a class=\"tag-cloud-link\">Tag</a>` markup. You can further tailor this part based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_html(entity_id: str, html: str) -> list[EntityPatchRequest]:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Extract the text of all 'a' tags with class 'tag-cloud-link'\n",
    "    tag_texts = [\n",
    "        a.get_text(strip=True) for a in soup.find_all(\"a\", class_=\"tag-cloud-link\")\n",
    "    ]\n",
    "\n",
    "    resource = URIRef(entity_id)\n",
    "\n",
    "    payloads = []\n",
    "\n",
    "    for value in tag_texts:\n",
    "        payloads.append(\n",
    "            create_entity_patch_request(\n",
    "                resource, URIRef(\"http://schema.org/keywords\"), Literal(value)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Main Function\n",
    "\n",
    "This is the main notebook function code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    await create_or_update_kg_using_sitemap(\n",
    "        configuration=configuration,\n",
    "        key=WORDLIFT_KEY,\n",
    "        sitemap_url=SITEMAP_URL,\n",
    "        types=OUTPUT_TYPES,\n",
    "        concurrency=1,\n",
    "        import_url_callback=await import_url_factory(\n",
    "            configuration=configuration, types=OUTPUT_TYPES\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
